{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separated-working",
   "metadata": {},
   "source": [
    "# Chi Square Test\n",
    "\n",
    "\n",
    "https://passel2.unl.edu/view/lesson/9beaa382bf7e/8#:~:text=If%20your%20chi%2Dsquare%20calculated,to%20reject%22%20your%20null%20hypothesis.\n",
    "\n",
    "If your chi-square calculated value is greater than the chi-square critical value, then you reject your null hypothesis.\n",
    "Rejecting hypothesis means we assume something other than chance was at play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "human-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_value=6.35 # value for 0.01 configence (should only occur in 0.01 of all cases other than by chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interior-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact match shapes (1819808, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_parquet('sources/metadata.parquet', engine='pyarrow')\n",
    "#df_large = pd.read_parquet('sources/metadata-large.parquet', engine='pyarrow')\n",
    "\n",
    "exact_matches = pd.read_parquet(\"../results/artists_exact_match_large.parquet\", engine='pyarrow')\n",
    "assert \"artists\" in exact_matches.columns, f'artists is not in {exact_matches.columns}'\n",
    "assert \"num_artists\" in exact_matches.columns, f'num_artists is not in {exact_matches.columns}'\n",
    "\n",
    "print(f'exact match shapes {exact_matches.shape}')\n",
    "\n",
    "# read excel_artist_names\n",
    "import my_utils\n",
    "\n",
    "excel_artist_names = my_utils.read_lines_as_list(\"../sources/excel_artists_copy_paste_name.txt\")\n",
    "hundred_artist_names = excel_artist_names[0:100]\n",
    "ten_artist_names = excel_artist_names[0:10]\n",
    "\n",
    "\n",
    "artist_mentions = pd.read_parquet('../results/artist_mentions.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "further-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def read_stopwords():\n",
    "    # from https://gist.github.com/sebleier/554280\n",
    "    return my_utils.read_lines_as_list(\"stopwords.txt\")\n",
    "\n",
    "def compute_freq(df, col, sw):\n",
    "    # print(sw)\n",
    "    freq = defaultdict(lambda: 0)\n",
    "    for i, row in df.iterrows():\n",
    "        string = row[col]\n",
    "        for s in re.split(\"[, \\-!?:]+\", string):\n",
    "            s=s.strip().lower()\n",
    "            if s not in sw:\n",
    "                if len(s)>0:\n",
    "                    freq[s]=freq[s]+1\n",
    "    return freq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "automated-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "stopwords=read_stopwords()\n",
    "stopwords.append(\"greg\")\n",
    "stopwords.append(\"rutkowski\")\n",
    "\n",
    "freqs = compute_freq(exact_matches, \"prompt\", stopwords)\n",
    "print(f'finished')\n",
    "\n",
    "greg_df = my_utils.exact_match_dataframe(exact_matches, \"greg rutkowski\")\n",
    "freqs_greg = compute_freq(greg_df, \"prompt\", stopwords)\n",
    "print(f'finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "desperate-tenant",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'freqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(freqs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m items in plain, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(freqs_greg\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m items in greg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m sum_plain \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m freqs\u001b[38;5;241m.\u001b[39mvalues():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'freqs' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "print(f'{len(freqs.keys())} items in plain, {len(freqs_greg.keys())} items in greg')\n",
    "\n",
    "sum_plain = 0\n",
    "for i in freqs.values():\n",
    "    sum_plain+=i\n",
    "    \n",
    "sum_greg = 0\n",
    "for i in freqs_greg.values():\n",
    "    sum_greg+=i\n",
    "\n",
    "word_chi_values ={}    \n",
    "for w, freq_greg in freqs_greg.items():\n",
    "    word_greg = freq_greg\n",
    "    word_plain = freqs[w]\n",
    "    others_greg = sum_greg - word_greg\n",
    "    others_plain = sum_plain - word_plain\n",
    "    total = sum_greg + sum_plain\n",
    "    word = word_greg + word_plain\n",
    "    others = others_greg + others_plain\n",
    "    expected_word_greg = (word * sum_greg) / total\n",
    "    expected_word_plain = (word * sum_plain) / total\n",
    "    expected_others_greg = (others * sum_greg) / total\n",
    "    expected_others_plain = (others * sum_plain) / total\n",
    "    word_chi_values[w] = math.pow(word_greg - expected_word_greg,2)/expected_word_greg \\\n",
    "        + math.pow(word_plain - expected_word_plain,2)/expected_word_plain \\\n",
    "        + math.pow(others_greg - expected_others_greg,2)/expected_others_greg\\\n",
    "        + math.pow(others_plain - expected_others_plain,2)/expected_others_plain\n",
    "    \n",
    "    \n",
    "    #print(f'{word_greg} | {word_plain} || {word}')\n",
    "    #print(f'{others_greg} | {others_plain} || {others}')\n",
    "    #print(f'{sum_greg} | {sum_plain} || {total}')\n",
    "    \n",
    "    #print(f'{expected_word_greg} | {expected_word_plain}')\n",
    "    #print(f'{expected_others_greg} | {expected_others_plain}')\n",
    "    #print(f'{w} --> {word_chi_values[w]}')\n",
    "    \n",
    "#print(word_chi_values)\n",
    "\n",
    "chi_values = pd.DataFrame.from_dict(word_chi_values, orient=\"index\", columns = [\"chi_values\"])\n",
    "chi_values.index.name = 'word'\n",
    "\n",
    "chi_values.sort_values(\"chi_values\", axis=0, ascending=False, inplace=True)\n",
    "chi_values.reset_index(inplace=True)\n",
    "\n",
    "print(f'amount of words with higher than threshold chi value: {chi_values[chi_values[\"chi_values\"]>=chi_square_value].shape[0]}')\n",
    "\n",
    "print(chi_values.head(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-wisdom",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my env conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
