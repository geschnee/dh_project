{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "boring-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('sources/metadata.parquet', engine='pyarrow')\n",
    "df_large = pd.read_parquet('sources/metadata-large.parquet', engine='pyarrow')\n",
    "\n",
    "\n",
    "# read excel_artist_names\n",
    "import my_utils\n",
    "\n",
    "excel_artist_names = my_utils.read_lines_as_list(\"sources/excel_artists_copy_paste_name.txt\")\n",
    "hundred_artist_names =  excel_artist_names[0:100]\n",
    "assert len(hundred_artist_names) == 100\n",
    "ten_artist_names = excel_artist_names[0:10]\n",
    "assert len(ten_artist_names) == 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"prompt\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vulnerable-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv for human readability\n",
    "df.to_csv(\"sources/metadata.csv\", escapechar = \"\\\\\")\n",
    "df_large.to_csv(\"sources/metadata-large.csv\", escapechar = \"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-moderator",
   "metadata": {},
   "source": [
    "# Exact matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-casting",
   "metadata": {},
   "source": [
    "## Extract artists from Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arranged-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"prompt\", \"image_name\"]\n",
    "\n",
    "cp = df_large[cols].copy()\n",
    "cp = cp.drop_duplicates(subset=\"prompt\")\n",
    "artist_names = excel_artist_names\n",
    "artist_names = [x.lower() for x in artist_names]\n",
    "\n",
    "cp['artists'] = cp['prompt'].map(\n",
    "        lambda p: my_utils.extract_artists_exact(p, artist_names))\n",
    "cp[\"num_artists\"] = cp['artists'].map(\n",
    "        lambda p: len(p))\n",
    "cp.to_parquet(\"results/artists_exact_match_large.parquet\")\n",
    "cp.to_csv(\"results/artists_exact_match_large.csv\", escapechar=\"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-mailing",
   "metadata": {},
   "source": [
    "## Count Artist Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_matches = pd.read_parquet('results/artists_exact_match_large.parquet', engine='pyarrow')\n",
    "\n",
    "\n",
    "\n",
    "cols = [\"artist\", \"mentions\"]\n",
    "\n",
    "artist_mentions =  pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "for name in excel_artist_names:\n",
    "    #print(entry)\n",
    "    new_row = dict()\n",
    "    new_row['artist'] = name\n",
    "    new_row['mentions'] = my_utils.exact_match_dataframe(exact_matches, name).shape[0]\n",
    "    \n",
    "    new_row = pd.Series(new_row)\n",
    "    #print(new_row)\n",
    "    \n",
    "    artist_mentions = pd.concat([artist_mentions, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "artist_mentions.sort_values(\"mentions\", axis=0, ascending=False)\n",
    "    \n",
    "artist_mentions.to_csv(\"results/artist_mentions.csv\", escapechar = \"\\\\\")\n",
    "artist_mentions.to_parquet(\"results/artist_mentions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-interference",
   "metadata": {},
   "source": [
    "# Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-bicycle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import my_utils\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "n = 1000\n",
    "similarity_threshold = 0.8\n",
    "\n",
    "df_reduced = df.head(n).copy()\n",
    "assert df_reduced.shape[0] == n, f'shape is {df_reduced.shape[0]}'\n",
    "\n",
    "artist_list = hundred_artist_names\n",
    "df_reduced['artists'] = df_reduced['prompt'].map(\n",
    "        lambda p: my_utils.extract_artists_fuzzy(p, artist_list, similarity_threshold))\n",
    "df_reduced.to_parquet(f'{n}_entries.parquet')\n",
    "df_reduced.to_csv(f'{n}_entries.csv')\n",
    "\n",
    "duration = (time.time()-starttime)\n",
    "print(f'processing took {duration/60} minutes, average {duration/n} seconds per row for {len(artist_list)} artists')\n",
    "\n",
    "goal = 1600000\n",
    "print(f'for {goal} entries it would take approximately {duration/n * goal / 60 / 60} hours')\n",
    "\n",
    "\n",
    "df_reduced['artists_amount'] = df_reduced['artists'].apply(\n",
    "        lambda query: len(query))\n",
    "    \n",
    "entries_with_artists = df_reduced.loc[df_reduced['artists_amount'] > 0, [\"image_name\", \"prompt\",\"user_name\",\"artists\",\"artists_amount\"]]\n",
    "entries_with_artists.to_parquet(\"artists_filtered.parquet\")\n",
    "entries_with_artists.to_csv(\"artists_filtered.csv\")\n",
    "\n",
    "# prognose: 933.333333333 stunden für den gesamten Datensatz (mit allen Namen aus )\n",
    "\n",
    "# prognose: 0.11 * 1600000 /60 /60 = 48 stunden für nur die Namen aus 100_copy_paste_names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-bahrain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my env conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
