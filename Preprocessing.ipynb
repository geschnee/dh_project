{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('sources/metadata.parquet', engine='pyarrow')\n",
    "df_large = pd.read_parquet('sources/metadata-large.parquet', engine='pyarrow')\n",
    "\n",
    "\n",
    "# read excel_artist_names\n",
    "import my_utils\n",
    "\n",
    "excel_artist_names = my_utils.read_lines_as_list(\"sources/excel_artists_copy_paste_name.txt\")\n",
    "hundred_artist_names =  excel_artist_names[0:100]\n",
    "assert len(hundred_artist_names) == 100\n",
    "ten_artist_names = excel_artist_names[0:10]\n",
    "assert len(ten_artist_names) == 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"prompt\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv for human readability\n",
    "df.to_csv(\"sources/metadata.csv\", escapechar = \"\\\\\")\n",
    "df_large.to_csv(\"sources/metadata-large.csv\", escapechar = \"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-prototype",
   "metadata": {},
   "source": [
    "# Exact matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-treat",
   "metadata": {},
   "source": [
    "## Extract artists from Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"prompt\", \"image_name\"]\n",
    "\n",
    "cp = df_large[cols].copy()\n",
    "cp = cp.drop_duplicates(subset=\"prompt\")\n",
    "artist_names = excel_artist_names\n",
    "artist_names = [x.lower() for x in artist_names]\n",
    "\n",
    "cp['artists'] = cp['prompt'].map(\n",
    "        lambda p: my_utils.extract_artists_exact(p, artist_names))\n",
    "cp[\"num_artists\"] = cp['artists'].map(\n",
    "        lambda p: len(p))\n",
    "cp.to_parquet(\"results/artists_exact_match_large.parquet\")\n",
    "cp.to_csv(\"results/artists_exact_match_large.csv\", escapechar=\"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-cattle",
   "metadata": {},
   "source": [
    "## Count Artist Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revised-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt         object\n",
      "image_name     object\n",
      "artists        object\n",
      "num_artists     int64\n",
      "dtype: object\n",
      "0 Alvar Aalto\n",
      "analysing 1 artists took 0.01518559455871582 minutes\n",
      "time remaining estimate 52.8914258480072 minutes\n",
      "1 Slim Aarons\n",
      "analysing 2 artists took 0.030604982376098634 minutes\n",
      "time remaining estimate 53.28327431678772 minutes\n",
      "2 Edwin Austin Abbey\n",
      "analysing 3 artists took 0.046196266015370684 minutes\n",
      "time remaining estimate 53.603067333168454 minutes\n",
      "3 Gertrude Abercrombie\n",
      "analysing 4 artists took 0.06205739974975586 minutes\n",
      "time remaining estimate 53.9899377822876 minutes\n",
      "4 Marina Abramović\n",
      "analysing 5 artists took 0.07790478467941284 minutes\n",
      "time remaining estimate 54.20614917993546 minutes\n",
      "5 Tomma Abts\n",
      "analysing 6 artists took 0.09367370208104452 minutes\n",
      "time remaining estimate 54.299522639645474 minutes\n",
      "6 Vito Acconci\n",
      "analysing 7 artists took 0.10877883831659953 minutes\n",
      "time remaining estimate 54.03200297525951 minutes\n",
      "7 Andreas Achenbach\n",
      "analysing 8 artists took 0.12386554876963297 minutes\n",
      "time remaining estimate 53.81958094040553 minutes\n",
      "8 Norman Ackroyd\n",
      "analysing 9 artists took 0.13885962963104248 minutes\n",
      "time remaining estimate 53.615245885319176 minutes\n",
      "9 Ansel Adams\n",
      "analysing 10 artists took 0.1538102587064107 minutes\n",
      "time remaining estimate 53.43368387460709 minutes\n",
      "10 Arthur Adams\n",
      "analysing 11 artists took 0.16884251832962036 minutes\n",
      "time remaining estimate 53.308187832615594 minutes\n",
      "11 Neal Adams\n",
      "analysing 12 artists took 0.18489678303400675 minutes\n",
      "time remaining estimate 53.49680255783929 minutes\n",
      "12 Josh Adamski\n",
      "analysing 13 artists took 0.20109114646911622 minutes\n",
      "time remaining estimate 53.69133610725403 minutes\n",
      "13 Charles Addams\n",
      "analysing 14 artists took 0.21683271725972494 minutes\n",
      "time remaining estimate 53.74353777794611 minutes\n",
      "14 Etel Adnan\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import my_utils\n",
    "import time\n",
    "\n",
    "excel_artist_names = my_utils.read_lines_as_list(\"sources/excel_artists_copy_paste_name.txt\")\n",
    "exact_matches = pd.read_parquet('results/artists_exact_match_large.parquet', engine='pyarrow')\n",
    "print(exact_matches.dtypes)\n",
    "\n",
    "\n",
    "cols = [\"artist\", \"mentions\"]\n",
    "\n",
    "artist_mentions =  pd.DataFrame(columns=cols)\n",
    "\n",
    "starttime = time.time()\n",
    "c=0\n",
    "for name in excel_artist_names:\n",
    "    print(f'{c} {name}',flush=True)\n",
    "    \n",
    "    \n",
    "    c+=1\n",
    "    if c == 15:\n",
    "          break\n",
    "    new_row = dict()\n",
    "    new_row['artist'] = name\n",
    "    mdf = my_utils.exact_match_dataframe(exact_matches, name)\n",
    "    #print(mdf)\n",
    "    new_row['mentions'] = mdf.shape[0]\n",
    "    \n",
    "    new_row = pd.Series(new_row)\n",
    "    #print(new_row)\n",
    "    \n",
    "    artist_mentions = pd.concat([artist_mentions, new_row.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    duration = time.time() - starttime\n",
    "    print(f'analysing {c} artists took {duration / 60} minutes',flush=True)\n",
    "    print(f'time remaining estimate {(duration/c)*(len(excel_artist_names)-c)/60} minutes',flush=True)\n",
    "\n",
    "artist_mentions.sort_values(\"mentions\", axis=0, ascending=False)\n",
    "    \n",
    "artist_mentions.to_csv(\"results/artist_mentions.csv\", escapechar = \"\\\\\")\n",
    "artist_mentions.to_parquet(\"results/artist_mentions.parquet\")\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-lawsuit",
   "metadata": {},
   "source": [
    "# Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-playing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import my_utils\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "n = 1000\n",
    "similarity_threshold = 0.8\n",
    "\n",
    "df_reduced = df.head(n).copy()\n",
    "assert df_reduced.shape[0] == n, f'shape is {df_reduced.shape[0]}'\n",
    "\n",
    "artist_list = hundred_artist_names\n",
    "df_reduced['artists'] = df_reduced['prompt'].map(\n",
    "        lambda p: my_utils.extract_artists_fuzzy(p, artist_list, similarity_threshold))\n",
    "df_reduced.to_parquet(f'{n}_entries.parquet')\n",
    "df_reduced.to_csv(f'{n}_entries.csv')\n",
    "\n",
    "duration = (time.time()-starttime)\n",
    "print(f'processing took {duration/60} minutes, average {duration/n} seconds per row for {len(artist_list)} artists')\n",
    "\n",
    "goal = 1600000\n",
    "print(f'for {goal} entries it would take approximately {duration/n * goal / 60 / 60} hours')\n",
    "\n",
    "\n",
    "df_reduced['artists_amount'] = df_reduced['artists'].apply(\n",
    "        lambda query: len(query))\n",
    "    \n",
    "entries_with_artists = df_reduced.loc[df_reduced['artists_amount'] > 0, [\"image_name\", \"prompt\",\"user_name\",\"artists\",\"artists_amount\"]]\n",
    "entries_with_artists.to_parquet(\"artists_filtered.parquet\")\n",
    "entries_with_artists.to_csv(\"artists_filtered.csv\")\n",
    "\n",
    "# prognose: 933.333333333 stunden für den gesamten Datensatz (mit allen Namen aus )\n",
    "\n",
    "# prognose: 0.11 * 1600000 /60 /60 = 48 stunden für nur die Namen aus 100_copy_paste_names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-assets",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my env conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
