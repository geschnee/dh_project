{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mighty-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('../sources/metadata.parquet', engine='pyarrow')\n",
    "df_large = pd.read_parquet('../sources/metadata-large.parquet', engine='pyarrow')\n",
    "\n",
    "\n",
    "# read excel_artist_names\n",
    "import my_utils\n",
    "artist_info = pd.read_csv(\"../sources/artist_info.csv\", sep=\"\\t\")\n",
    "\n",
    "for col in artist_info.columns:\n",
    "    if \"Unnamed\" in col:\n",
    "        artist_info.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "undefined-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lastname     firstname               cp_name  \\\n",
      "0        Aalto         Alvar           Alvar Aalto   \n",
      "1       Aarons          Slim           Slim Aarons   \n",
      "2        Abbey  Edwin Austin    Edwin Austin Abbey   \n",
      "3  Abercrombie      Gertrude  Gertrude Abercrombie   \n",
      "4    Abramović        Marina      Marina Abramović   \n",
      "\n",
      "                          tags pseudonyms  \n",
      "0  architecture, high contrast        NaN  \n",
      "1  vibrant, photography, scene        NaN  \n",
      "2               scene, realism        NaN  \n",
      "3            surrealism, dark,        NaN  \n",
      "4           scene, photography        NaN  \n",
      "        lastname firstname           cp_name                        tags  \\\n",
      "3472   Underwood    George  George Underwood                         NaN   \n",
      "3473     Vivanco     Kelly     Kelly Vivanco                         NaN   \n",
      "3474     Volegov  Vladimir  Vladimir Volegov  scene, portrait, landscape   \n",
      "3475       Wrona  Angelina    Angelina Wrona                         NaN   \n",
      "3476  Zouravliov     Vania  Vania Zouravliov                         NaN   \n",
      "\n",
      "     pseudonyms  \n",
      "3472        NaN  \n",
      "3473        NaN  \n",
      "3474        NaN  \n",
      "3475        NaN  \n",
      "3476        NaN  \n"
     ]
    }
   ],
   "source": [
    "print(artist_info.head())\n",
    "print(artist_info.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tough-magnet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lastname     firstname               cp_name  \\\n",
      "0        Aalto         Alvar           Alvar Aalto   \n",
      "1       Aarons          Slim           Slim Aarons   \n",
      "2        Abbey  Edwin Austin    Edwin Austin Abbey   \n",
      "3  Abercrombie      Gertrude  Gertrude Abercrombie   \n",
      "4    Abramović        Marina      Marina Abramović   \n",
      "\n",
      "                          tags pseudonyms  \n",
      "0  architecture, high contrast        NaN  \n",
      "1  vibrant, photography, scene        NaN  \n",
      "2               scene, realism        NaN  \n",
      "3            surrealism, dark,        NaN  \n",
      "4           scene, photography        NaN  \n",
      "an artist with multiple names ['Sabbas Apterus', 'Peter Polach']\n",
      "an artist with multiple names ['Ron Arad', 'Giorgione']\n",
      "an artist with multiple names ['Alexander Archipenko', 'Olexandr Archipenko']\n",
      "an artist with multiple names ['Artgerm', 'Stanley Lau']\n",
      "an artist with multiple names ['Ralph Bakshi', 'Giorgio Barbarelli da Castelfranco']\n",
      "an artist with multiple names ['Artur Bordalo', 'Bordalo II']\n",
      "an artist with multiple names ['Mikalojus Konstantinas Ciurlionis', 'Mikalojus Konstantinas Čiurlionis']\n",
      "an artist with multiple names ['Craola', 'Greg Simkins']\n",
      "an artist with multiple names ['Kelly Freas', 'Frank Kelly Freas']\n",
      "an artist with multiple names ['H. R. (Hans Ruedi) Giger', 'Giger']\n",
      "an artist with multiple names ['Jean Giraud', 'Moebius', 'Mœbius']\n",
      "an artist with multiple names ['Josan Gonzalez', 'Death Burger']\n",
      "an artist with multiple names ['Matthias Grünewald', 'Gothart', 'Neithardt']\n",
      "an artist with multiple names ['Friedensreich Regentag Dunkelbunt Hundertwasser', 'Hundertwasser']\n",
      "an artist with multiple names ['Hayao Miyazaki', 'Studio Ghibli']\n",
      "an artist with multiple names ['RHADS', 'Artem Chebokha']\n",
      "an artist with multiple names ['Jakub Różalski', 'Jakub Rozalski']\n",
      "an artist with multiple names ['Cedric Seaut', 'Keos Masons']\n",
      "an artist with multiple names ['Lois van Baarle', 'Loish']\n",
      "an artist with multiple names ['Mike Winkelmann', 'Beeple']\n",
      "an artist with multiple names ['Didier Barra', 'Monsù Desiderio']\n",
      "an artist with multiple names ['Artem Chebokha', 'RHADS']\n",
      "an artist with multiple names ['François De Nomé', 'Monsù Desiderio']\n",
      "an artist with multiple names ['Henri Rogers', 'Henry Rogers']\n",
      "an artist with multiple names ['Ryky', 'Zdenek Cehelsky']\n",
      "an artist with multiple names ['Arthur Skizhali-Weiss', 'Артур Скижали-Вейc']\n",
      "an artist with multiple names ['Toyen', 'Marie Čermínová']\n",
      "an artist with multiple names ['Ziraldo', 'Ziraldo Alves Pinto']\n",
      "an artist with multiple names ['Артур Скижали-Вейс', 'Arthur Skizhali-Weiss']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(artist_info.head())\n",
    "\n",
    "artist_dict = {}\n",
    "# keys are the copy_paste names of the artists\n",
    "# values are lists of aliases of the artists\n",
    "\n",
    "for index, row in artist_info.iterrows():\n",
    "    artist_name = row.cp_name.strip(\" \")\n",
    "    artist_dict[artist_name] = [artist_name]\n",
    "    \n",
    "    if row.pseudonyms is not np.nan:\n",
    "        for pseudonym in row.pseudonyms.split(\",\"):\n",
    "            pseudonym = pseudonym.strip()\n",
    "            #print(f'{row.cp_name} {pseudonym}')\n",
    "            artist_dict[artist_name].append(pseudonym)\n",
    "        print(f'an artist with multiple names {artist_dict[artist_name]}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bronze-accordance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of artists: 3477\n"
     ]
    }
   ],
   "source": [
    "print(f'number of artists: {len(artist_dict.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-lawsuit",
   "metadata": {},
   "source": [
    "## Timeframe analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "durable-intellectual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-06 21:59:00+00:00\n",
      "2022-08-20 13:33:00+00:00\n"
     ]
    }
   ],
   "source": [
    "print(df_large.timestamp.min())\n",
    "print(df_large.timestamp.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-electronics",
   "metadata": {},
   "source": [
    "## User analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "skilled-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of unique users (10381,)\n"
     ]
    }
   ],
   "source": [
    "print(f'amount of unique users {df_large.user_name.unique().shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competent-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000000, 13)\n",
      "89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45    224010\n",
      "deleted-account                                                      93543\n",
      "481f5d1579a33041518382518a5e108cfc1fea95f880d081023f533eb1afd82a     49577\n",
      "5477db661bbe6ff9fd509daf812fe50af4b6216f2b296c3cbf91c6b9e528fdce     38137\n",
      "ac2524ee4169c7f644f783de87f9bbfb96fa68b6e116dfb1f8b65274edaee97a     37524\n",
      "                                                                     ...  \n",
      "46b8b7b984d1d18b88cfcbaeac0728bb5aec9ef5c21e28831e8677d0621ed62e         1\n",
      "19aba8d820816e84f8866140660d476c013858c2b6407b98bc5db41218095ee4         1\n",
      "49788eeed56abc8f376073ce17f8097fdbdd3f70274ae2496c34f9543686a865         1\n",
      "d6473a7a475e429100b5178a0298ebdfdf8d8d27bfc6eceed9f5a8d148c4a4b4         1\n",
      "5e2d286338eb8cad8abb71c28c4d10cde5e4777a5ab8f9e39021c940b5de613f         1\n",
      "Name: user_name, Length: 10381, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_large.shape)\n",
    "print(df_large.user_name.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lightweight-annex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    image_name  \\\n",
      "531  5c91c55e-2997-4c8f-a352-d7a55c9101ad.webp   \n",
      "532  23756e3c-a208-4b22-9da0-389a20fc8fd1.webp   \n",
      "533  c74875dd-4fca-4d3c-b72b-cd1857386c1c.webp   \n",
      "534  dba6e669-c61f-4858-bdea-fa1c1632b772.webp   \n",
      "535  a78de037-1e01-449a-80d9-09fac1957160.webp   \n",
      "536  6027269e-c39a-4f7f-a06a-4a2f6b57d7e3.webp   \n",
      "537  a61eb078-41ce-4358-ba3e-2402c61a32b4.webp   \n",
      "538  827309b2-38cd-4fdd-a627-042e50fc5f8a.webp   \n",
      "539  03015b95-b837-43f7-a5e5-6cf1814016b6.webp   \n",
      "540  0924f662-e63f-4d6e-8757-ac2e061cf273.webp   \n",
      "\n",
      "                                                                                                                                                                                                                                        prompt  \\\n",
      "531  mount epic expedition bloodswarmer screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "532  mount epic expedition bloodswarmer screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "533  mount epic expedition bloodswarmer screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "534  mount epic expedition bloodswarmer screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "535       mount epic swift olive raptor screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "536       mount epic swift olive raptor screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "537       mount epic swift olive raptor screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "538       mount epic swift olive raptor screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "539       mount epic great purple elekk screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "540       mount epic great purple elekk screenshot world of warcraft mounts worldboss bioluminecant light concept sketch art and by feng zhu alena aenami artworks in 4 k beeple, by thomas kinkade heartstone overwatch blizzard 3 d rtx hdr    \n",
      "\n",
      "     part_id        seed  step   cfg  sampler  width  height  \\\n",
      "531        1  1306437380    50  12.0        8    768     512   \n",
      "532        1  1341991387    50  12.0        8    768     512   \n",
      "533        1  2726036640    50  12.0        8    768     512   \n",
      "534        1  1629868457    50  12.0        8    768     512   \n",
      "535        1  2797312217    50  12.0        8    768     512   \n",
      "536        1  1770056517    50  12.0        8    768     512   \n",
      "537        1  3673534016    50  12.0        8    768     512   \n",
      "538        1  1681093498    50  12.0        8    768     512   \n",
      "539        1  1124766567    50  12.0        8    768     512   \n",
      "540        1  2844730023    50  12.0        8    768     512   \n",
      "\n",
      "                                                            user_name  \\\n",
      "531  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "532  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "533  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "534  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "535  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "536  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "537  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "538  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "539  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "540  89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45   \n",
      "\n",
      "                    timestamp  image_nsfw  prompt_nsfw  \n",
      "531 2022-08-20 09:30:00+00:00    0.080630     0.001065  \n",
      "532 2022-08-20 09:30:00+00:00    0.080592     0.001065  \n",
      "533 2022-08-20 09:30:00+00:00    0.075654     0.001065  \n",
      "534 2022-08-20 09:30:00+00:00    0.050372     0.001065  \n",
      "535 2022-08-20 10:59:00+00:00    0.085626     0.002059  \n",
      "536 2022-08-20 10:59:00+00:00    0.091593     0.002059  \n",
      "537 2022-08-20 10:59:00+00:00    0.066272     0.002059  \n",
      "538 2022-08-20 10:59:00+00:00    0.082520     0.002059  \n",
      "539 2022-08-20 11:02:00+00:00    0.131847     0.001194  \n",
      "540 2022-08-20 11:02:00+00:00    0.133744     0.001194  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(df_large[df_large.user_name == \"89bebf4f200a853ac9a7b4dfec1edb160ade299fd60db12d0752bbfd882c6f45\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southwest-haiti",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000000, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_large.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "geological-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1819808"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_large[\"prompt\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tested-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv for human readability\n",
    "df.to_csv(\"../sources/metadata.csv\", escapechar = \"\\\\\")\n",
    "df_large.to_csv(\"../sources/metadata-large.csv\", escapechar = \"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-swaziland",
   "metadata": {},
   "source": [
    "# Exact matching\n",
    "\n",
    "Exact matching by name and known pseudonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-material",
   "metadata": {},
   "source": [
    "## Extract artists + styles from unique Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "published-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of styles: 192\n"
     ]
    }
   ],
   "source": [
    "style_names= my_utils.read_lines_as_list(\"../sources/styles.txt\")\n",
    "print(f'number of styles: {len(style_names)}')\n",
    "# print(f'style names: {style_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique prompts\n",
    "cols = [\"prompt\", \"image_name\",\"user_name\"]\n",
    "\n",
    "extract_artists_styles = df_large[cols].copy()\n",
    "extract_artists_styles = extract_artists_styles.drop_duplicates(subset=\"prompt\")\n",
    "\n",
    "extract_artists_styles['artists'] = extract_artists_styles['prompt'].map(\n",
    "        lambda p: my_utils.extract_artists_exact(p, artist_dict))\n",
    "extract_artists_styles[\"num_artists\"] = extract_artists_styles['artists'].map(\n",
    "        lambda p: len(p))\n",
    "\n",
    "print(\"artists extracted\")\n",
    "print(extract_artists_styles.head())\n",
    "\n",
    "extract_artists_styles['styles'] = extract_artists_styles['prompt'].map(\n",
    "        lambda p: my_utils.extract_styles_exact(p, style_names))\n",
    "extract_artists_styles[\"num_styles\"] = extract_artists_styles['styles'].map(\n",
    "        lambda p: len(p))\n",
    "\n",
    "\n",
    "print(extract_artists_styles.head())\n",
    "extract_artists_styles.to_parquet(\"../results/artists_exact_match_large.parquet\")\n",
    "extract_artists_styles.to_csv(\"../results/artists_exact_match_large.csv\", escapechar=\"\\\\\")\n",
    "print(f'Artists extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_artists_styles.sort_values([\"num_styles\"], ascending=False, inplace=True)\n",
    "print(f'There are some prompts with a lot of mentioned styles:\\n{extract_artists_styles.num_styles.describe()}')\n",
    "print(extract_artists_styles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-collection",
   "metadata": {},
   "source": [
    "## Count Artist Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import my_utils\n",
    "import time\n",
    "\n",
    "exact_matches = pd.read_parquet('../results/artists_exact_match_large.parquet', engine='pyarrow')\n",
    "print(f'exact_matches.dtypes {exact_matches.dtypes}')\n",
    "\n",
    "artist_names = artist_dict.keys()\n",
    "\n",
    "cols = [\"artist\", \"mentions\", \"style_mentions\"]\n",
    "\n",
    "artist_mentions =  pd.DataFrame(columns=cols)\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "for index, name in enumerate(artist_names):\n",
    "    \n",
    "    new_row = dict()\n",
    "    new_row['artist'] = name\n",
    "    mdf = my_utils.exact_match_dataframe(exact_matches, name)\n",
    "    new_row['mentions'] = mdf.shape[0]\n",
    "    new_row['style_mentions'] = mdf.num_styles.sum() # style_mentions sum of all mentioned styles in prompts that contain the artist\n",
    "    \n",
    "    new_row = pd.Series(new_row)\n",
    "    \n",
    "    artist_mentions = pd.concat([artist_mentions, new_row.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    duration = time.time() - starttime\n",
    "    \n",
    "    if index % 1000 == 0:\n",
    "        c = index + 1\n",
    "        print(f'analysing {c} artists took {duration / 60} minutes',flush=True)\n",
    "        print(f'time remaining estimate {(duration/c)*(len(artist_names)-c)/60} minutes',flush=True)\n",
    "\n",
    "artist_mentions.sort_values(\"mentions\", axis=0, ascending=False, inplace=True)\n",
    "    \n",
    "artist_mentions.to_csv(\"../results/artist_mentions.csv\", escapechar = \"\\\\\")\n",
    "artist_mentions.to_parquet(\"../results/artist_mentions.parquet\")\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-liability",
   "metadata": {},
   "source": [
    "# Count Style Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import my_utils\n",
    "import time\n",
    "\n",
    "style_names= my_utils.read_lines_as_list(\"../sources/styles.txt\")\n",
    "\n",
    "exact_matches = pd.read_parquet('../results/artists_exact_match_large.parquet', engine='pyarrow')\n",
    "print(exact_matches[exact_matches.num_styles > 0].head())\n",
    "\n",
    "\n",
    "cols = [\"style\", \"mentions\"]\n",
    "\n",
    "style_mentions =  pd.DataFrame(columns=cols)\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "for index, name in enumerate(style_names):\n",
    "    \n",
    "    new_row = dict()\n",
    "    new_row['style'] = name\n",
    "    mdf = my_utils.exact_match_dataframe_style(exact_matches, name)\n",
    "    #print(mdf)\n",
    "    new_row['mentions'] = mdf.shape[0]\n",
    "    #print(new_row['mentions'])\n",
    "    \n",
    "    new_row = pd.Series(new_row)\n",
    "    #print(new_row)\n",
    "    \n",
    "    style_mentions = pd.concat([style_mentions, new_row.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    duration = time.time() - starttime\n",
    "\n",
    "style_mentions.sort_values(\"mentions\", axis=0, ascending=False, inplace=True)\n",
    "style_mentions.reset_index(inplace=True)\n",
    "style_mentions.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "assert style_mentions[style_mentions[\"mentions\"]>0].shape[0]>0, f'No style mentions have been found, check the data.'\n",
    "\n",
    "print(style_mentions.head())\n",
    "\n",
    "style_mentions.to_csv(\"../results/style_mentions.csv\", escapechar = \"\\\\\")\n",
    "style_mentions.to_parquet(\"../results/style_mentions.parquet\")\n",
    "\n",
    "print(f'{style_mentions[style_mentions.mentions > 0].shape[0]} of {len(style_names)} styles have been found')\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(style_mentions.columns)\n",
    "\n",
    "\n",
    "assert style_mentions[style_mentions[\"mentions\"]>0].shape[0]>0, f'No style mentions have been found, check the data.'\n",
    "\n",
    "print(style_mentions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-meaning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my env conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
